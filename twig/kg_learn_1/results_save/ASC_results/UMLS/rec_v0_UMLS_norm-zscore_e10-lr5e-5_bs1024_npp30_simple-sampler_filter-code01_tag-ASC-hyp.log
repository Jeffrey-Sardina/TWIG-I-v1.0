['run_exp.py', '0', 'UMLS', '10', '5e-5', 'zscore', '1024', '30', '0', '1', 'simple', '1']
loading NN
done loading NN
loading dataset
UMLS
X_p: torch.Size([5216, 37])
X_p: torch.Size([661, 37])
X_p: torch.Size([652, 37])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
loading precalculated corruptions from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 10
Epoch 1 -- batch 0 / 6 loss: 0.13166280090808868
Epoch 2 -- batch 0 / 6 loss: 0.13337917625904083
Epoch 3 -- batch 0 / 6 loss: 0.12600620090961456
Epoch 4 -- batch 0 / 6 loss: 0.12662437558174133
Epoch 5 -- batch 0 / 6 loss: 0.1342041939496994
NOT Saving checkpoint at epoch 5
Epoch 6 -- batch 0 / 6 loss: 0.12489917129278183
Epoch 7 -- batch 0 / 6 loss: 0.1286548227071762
Epoch 8 -- batch 0 / 6 loss: 0.12734612822532654
Epoch 9 -- batch 0 / 6 loss: 0.12577848136425018
Epoch 10 -- batch 0 / 6 loss: 0.12898476421833038
NOT Saving checkpoint at epoch 10
Done Training!

==================================
Testing (cite this): dataloader for dataset UMLS
Testing (cite this): batch 0 / 1
ranks: tensor([193., 230., 178., 207., 170.,   1.,   1.,   6.,  80.,  94.,  99.,  75.,
         67., 183., 184., 185., 221.,  58., 191., 231., 253., 130.,  83.,  45.,
         52., 163.,  76.,  81., 112., 241., 240., 249., 250.,  23., 230., 134.,
        249., 244., 248., 240., 229., 220., 231., 233., 231.,  36., 243., 243.,
        255.,  86.,  74.,  13., 233.,  15., 229., 243., 236.,  12.,  19.,  17.,
        243., 229., 214., 227., 231., 222., 222., 213., 220., 145., 178., 204.,
        201.,  28.,   2.,  24.,   1., 127., 203., 211.,   3.,  40.,  82., 134.,
        214.,  84.,  32., 207., 134., 132., 239., 263., 259.,  25., 161.,  77.,
        240., 241., 216.,  92., 128., 236., 146., 118., 212., 225., 250., 253.,
        112., 257., 233.,  39., 116.,  19.,  18.,  21.,  27., 247., 233., 251.,
        196., 234.,  90., 197., 244.,  26.,  22., 151., 112.,  56., 215., 213.,
        163.,  42., 161., 204., 125., 188., 246., 258., 246., 157., 167., 169.,
          1.,   1.,   1.,  28., 199., 214., 210., 198., 207.,  66.,  98.,   5.,
          1.,   1.,   1., 140.,  19., 223., 120., 166., 216., 200., 155.,   9.,
        108.,  82., 231., 229.,  91., 129.,  94.,  26.,  86., 196.,  17.,  12.,
          2.,  55.,  16., 103.,  13., 212.,  81.,  87.,  11.,  47., 268., 209.,
        254., 234., 185., 230.,   1.,   1., 190., 159., 214., 180., 145., 135.,
        132., 222., 112., 230.,   7.,   1., 226., 198., 186., 188., 103., 181.,
          1.,  71.,  12.,  17., 150., 230., 176., 184., 181., 237., 237., 236.,
        236., 258., 121.,   2.,  37., 249., 200., 244., 250., 233., 244., 243.,
        244., 243.,  92.,  93.,  13., 202., 237., 226., 238., 246., 226., 245.,
        164., 212., 148., 105.,  77., 158.,  91.,   8., 235., 166., 243.,  92.,
         25.,  19.,  22., 100., 243.,  58., 222., 223., 219.,   8., 223., 209.,
        218.,  55., 135.,  38., 192., 200.,  62.,   4., 116.,  89.,  24., 114.,
        236.,   1., 181., 135.,  79., 192., 196., 256., 243., 209.,  10.,   6.,
          2., 203.,  44.,   1., 221., 203., 181., 157., 173., 181., 243., 202.,
        201., 225., 240., 229., 114., 199., 211., 253., 147., 252., 204., 135.,
         35.,  27., 116., 197., 212., 191., 207., 199., 180., 218.,  48.,  10.,
        167., 225.,  13., 223., 233., 236.,  57., 191., 141., 125., 211., 236.,
        233., 196., 187., 113., 194.,  87.,  32.,  26.,  30.,  33.,  35., 162.,
        234., 238., 241., 235., 215., 216., 216., 208., 231., 134., 220.,   1.,
         58., 196., 151.,  10., 241.,  41.,  87.,  89., 224.,   1., 132., 250.,
        242.,  69., 260., 179., 186.,  52., 255., 148., 123., 171., 184., 179.,
         23., 161., 123., 129., 125., 186., 154., 219.,  41.,  56., 183., 207.,
         64., 204., 214., 138.,  80., 223., 248., 204., 165., 133.,   1., 207.,
        215.,  20.,  15., 190., 211., 153.,   1.,  36., 249., 256., 210., 230.,
        234., 245., 252.,   5., 256.,  15., 228., 134., 135., 255.,  32., 169.,
        176., 193.,  27.,  14., 191.,   9., 192., 200., 222., 222., 192., 104.,
          4.,   1., 120.,   7., 141.,  46.,  49.,  55., 205., 213.,  94., 129.,
        119., 130., 166., 200., 207.,  35.,  32.,   6.,  10.,  22., 105., 198.,
        210., 193., 196., 195., 167.,  13., 209.,  19., 207., 195.,  19.,  14.,
        193.,  19., 209., 187., 139., 218., 236., 188., 243.,   1.,   7., 204.,
        211., 218., 210., 226.,  25., 223., 217., 177., 209., 113.,  85., 132.,
        109.,  87., 123.,  44.,  11., 169.,  60., 163., 186., 206., 150., 157.,
        151., 127.,   2.,   4.,   8., 227., 214., 199., 153., 190.,  88.,   3.,
        225., 229., 209., 201.,  13., 214.,  67.,  30.,   9., 237., 233., 236.,
         11., 223., 227., 177., 183., 190., 246., 246.,  35., 218., 170., 112.,
        223., 246., 236.,  14.,  29., 196., 232., 189.,  60., 135., 134.,  28.,
          8., 172., 125.,  58., 169.,   1., 105., 159., 200., 175., 192., 180.,
          4.,   1., 181., 201., 188.,  16.,  87., 185.,  12.,   9.,  52.,   5.,
         74.,  27.,  12., 145.,  25.,  75., 139., 148., 205., 133.,   1., 165.,
          1., 152., 102.,  40., 118., 135.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1., 151.,   1., 130.,   1.,  64.,  58.,   1.,   1.,   1.,   1.,
        147.,  77.,   1.,   1.,  21., 114.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.])
mr: 136.4662628173828
mrr: 0.10007116198539734
h1: 0.07822085916996002
h3: 0.0889570564031601
h5: 0.09969325363636017
h10: 0.12730062007904053
==================================

Done Testing!
done with training and eval
Experiments took 40 seconds
