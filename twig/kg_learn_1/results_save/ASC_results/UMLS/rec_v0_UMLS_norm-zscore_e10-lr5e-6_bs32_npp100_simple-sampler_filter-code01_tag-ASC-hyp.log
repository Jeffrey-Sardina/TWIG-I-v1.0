['run_exp.py', '0', 'UMLS', '10', '5e-6', 'zscore', '32', '100', '0', '1', 'simple', '1']
loading NN
done loading NN
loading dataset
UMLS
X_p: torch.Size([5216, 37])
X_p: torch.Size([661, 37])
X_p: torch.Size([652, 37])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
loading precalculated corruptions from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 10
Epoch 1 -- batch 0 / 163 loss: 0.1766275018453598
Epoch 2 -- batch 0 / 163 loss: 0.15234926342964172
Epoch 3 -- batch 0 / 163 loss: 0.12337546795606613
Epoch 4 -- batch 0 / 163 loss: 0.12947262823581696
Epoch 5 -- batch 0 / 163 loss: 0.12300055474042892
NOT Saving checkpoint at epoch 5
Epoch 6 -- batch 0 / 163 loss: 0.1501249223947525
Epoch 7 -- batch 0 / 163 loss: 0.1225946769118309
Epoch 8 -- batch 0 / 163 loss: 0.14753404259681702
Epoch 9 -- batch 0 / 163 loss: 0.14804072678089142
Epoch 10 -- batch 0 / 163 loss: 0.16057978570461273
NOT Saving checkpoint at epoch 10
Done Training!

==================================
Testing (cite this): dataloader for dataset UMLS
Testing (cite this): batch 0 / 21
ranks: tensor([195., 230., 181., 207., 164.,   1.,   1.,   4.,  69.,  91.,  89.,  60.,
         72., 187., 184., 179., 223.,  47., 190., 237., 255., 135.,  80.,  34.,
         54., 166.,  96.,  83., 110.,   1.,   1.,   1., 250., 126., 230., 123.,
        244., 241., 250., 242., 229., 223., 230., 234., 225., 128., 237., 243.,
        255., 202., 172.,  16., 237.,  21., 237., 243., 240.,  19.,  16.,  20.,
        243., 231., 233., 243., 241., 217., 223., 206., 217., 118., 187., 207.,
        118.,  24.,   1.,  40.,   3., 173., 203., 212.,  15.,  63.,  49., 140.,
        216.,  40.,  48., 190., 122.,  66.,  87.,   1.,   1.,  95., 136.,  36.,
        199., 240., 240., 231., 238., 247., 245., 240., 244., 244., 250., 253.,
         36., 250., 101., 103., 150., 159., 230., 190., 215., 255., 254., 257.,
        247., 244.,  60., 184., 246.,  30.,  31.,  16.,  23.,  62., 218., 195.,
         53.,   8.,  21., 149., 130., 220., 252., 258., 252.,  20., 194., 190.,
          1.,   1.,   1.,  33., 197., 207., 212., 204., 207., 135., 180., 139.,
        108.,  84.,  90.,  26., 134., 223., 116., 182., 212., 194., 148.,   8.,
        146.,  60., 231., 229., 154., 204., 175.,  52., 217., 197.,  23.,  11.,
         30.,  12.,  78.,  59.,   1.,  87., 256., 122.,   1.,  20.,   1.,   1.,
        245., 222., 193., 215.,   1.,   1., 109., 148., 169., 156., 145., 134.,
         89., 226., 116., 230.,   5.,   1., 224., 198., 179., 183., 174., 179.,
          1.,  82.,  51.,  86., 175., 230.,  49.,   1., 172., 228., 229., 235.,
        212., 153., 154.,   8., 110., 240., 140., 205., 236., 167., 237., 234.,
        245., 243., 142., 141.,  71., 214., 238., 232., 236., 246., 233., 255.,
        255., 255.,  69.,   1., 239., 206., 213.,  69., 242., 230., 243., 200.,
         94., 230., 180., 121., 243., 225., 224., 223., 202.,   3., 215., 127.,
        130.,  25.,  65.,   6.,  92.,  36.,  90.,   4.,  79.,  72., 101.,  49.,
        236.,   7.,  66., 135., 198., 231., 230., 256., 232., 234.,  83.,  33.,
         33., 240., 218.,  22., 238., 236., 237., 239., 230., 236., 239., 201.,
         28., 222., 232., 211.,   8., 189., 173.,   1.,  29., 251., 165., 135.,
         38.,   5.,  15., 166., 212., 195., 207., 200., 150., 200., 167.,  80.,
        168., 227., 119., 223., 194., 236.,  80., 149.,  88., 191., 175., 235.,
        218., 131.,   1.,   1., 184., 193., 245., 246., 246., 168., 194., 220.,
        185., 181., 229., 205., 203., 200., 206., 108., 196.,  11.,  36.,   7.,
         17.,  20.,  14.,   1., 240.,  37.,  85.,   7.,  22.,  24., 135.,   1.,
        259., 242., 260., 249., 240., 206., 255., 241., 249., 249., 214.,  78.,
        159., 187.,   1., 130., 134.,  78.,  97., 202., 163., 177., 208., 198.,
         34.,  74., 156.,  70., 186., 186., 134.,   1.,  36.,  88.,   1., 241.,
        233., 201.,  70., 161., 142., 207.,  87., 174., 255., 256., 170., 244.,
        244., 244., 256.,  18., 253.,   1., 178.,  89., 134., 255.,  57., 203.,
        171.,  77.,   1.,   1., 191.,   1., 193., 144., 223., 223., 148.,   1.,
          1.,   1.,   1.,   1.,   2.,   1.,  42.,  26., 145., 104.,  15., 121.,
        114., 126., 166., 207., 205.,  12., 112., 112.,  98., 119.,   1.,   1.,
        209., 203., 200., 202., 150., 126., 209.,   1., 206., 195.,  21., 111.,
        195., 116., 202., 190., 134., 214., 239., 227., 243.,  27., 103., 207.,
        167., 208., 191., 222.,   4., 169., 207.,  38.,  46.,  95.,  74., 142.,
        189., 124., 109.,  13., 118., 139., 159., 164., 189., 208., 158., 171.,
        120.,  89.,   1.,   1.,   1., 237., 208., 180., 189., 185., 173., 104.,
        229., 230.,   1.,   1., 101., 212.,  86.,  98., 109., 237., 217., 241.,
         83., 226., 229., 189., 217., 224., 246., 246., 149., 242., 201., 155.,
        244., 246., 242.,  97.,  39., 199., 235., 197.,  28., 127.,   3., 119.,
         36.,  57., 107.,  63., 169.,  20.,  25., 137., 202., 181., 196., 132.,
          1.,   1., 136., 200., 188.,   1.,   9., 192., 119.,  69.,  14.,  92.,
        159., 196.,  46., 227.,   1.,   1.,   1.,   1.,  28.,  31.,  55., 194.,
        254., 140.,   1.,  12.,  26., 135., 249., 253.,   1.,   1., 207., 200.,
          4.,   1., 132.,  60.,  23.,   4.,   1.,   1., 116., 131.,   1.,  21.,
          4.,  32.,   1.,   1.,  38.,  90., 241., 132.,  17., 248., 220., 118.,
        124., 174., 113.,  31.])
mr: 138.71778869628906
mrr: 0.11360739171504974
h1: 0.09662576764822006
h3: 0.10276073962450027
h5: 0.1150306761264801
h10: 0.12883435189723969
==================================

Done Testing!
done with training and eval
Experiments took 53 seconds
