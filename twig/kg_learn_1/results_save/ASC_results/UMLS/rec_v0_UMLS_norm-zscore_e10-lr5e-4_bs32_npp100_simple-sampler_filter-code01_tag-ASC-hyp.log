['run_exp.py', '0', 'UMLS', '10', '5e-4', 'zscore', '32', '100', '0', '1', 'simple', '1']
loading NN
done loading NN
loading dataset
UMLS
X_p: torch.Size([5216, 37])
X_p: torch.Size([661, 37])
X_p: torch.Size([652, 37])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
loading precalculated corruptions from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 10
Epoch 1 -- batch 0 / 163 loss: 0.1796870231628418
Epoch 2 -- batch 0 / 163 loss: 0.12054557353258133
Epoch 3 -- batch 0 / 163 loss: 0.058011531829833984
Epoch 4 -- batch 0 / 163 loss: 0.041902899742126465
Epoch 5 -- batch 0 / 163 loss: 0.09464053809642792
NOT Saving checkpoint at epoch 5
Epoch 6 -- batch 0 / 163 loss: 0.0800246149301529
Epoch 7 -- batch 0 / 163 loss: 0.04730472341179848
Epoch 8 -- batch 0 / 163 loss: 0.055561330169439316
Epoch 9 -- batch 0 / 163 loss: 0.046020206063985825
Epoch 10 -- batch 0 / 163 loss: 0.049138039350509644
NOT Saving checkpoint at epoch 10
Done Training!

==================================
Testing (cite this): dataloader for dataset UMLS
Testing (cite this): batch 0 / 21
ranks: tensor([  1.,   2.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1., 219.,   4.,   1.,   6.,
          2.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          7.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   7.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   3.,   1.,   1.,   1.,
          1.,  11.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   9.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,  10.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,  44.,   1., 140.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,  63.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   3.,   1.,   1.,   1.,   1.,  30., 152.,   1.,   1.,   1.,   1.,
          1.,   1.,   2.,   8.,   1.,  30.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   9.,   1.,   1.,   1.,   1.,   1.,   1.,   2.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,  42.,   1.,   1.,   1.,   4.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   5.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   7.,   1.,   1.,   1.,   1.,   1.,   1.,   1., 234.,  70., 135.,
          1.,   1.,   1.,   2.,   1.,   1.,  65.,   1.,   1.,   1.,   1.,  50.,
         10., 122.,   8.,   1.,   1.,   3.,   1.,   1.,   1.,   1.,   1.,  92.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,  99.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   6.,   1.,   1.,   7.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1., 101.,   8.,   8.,   2.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   6.,   1.,   1.,
          1.,   1.,   1.,   1.,   4.,   1.,   1.,   1.,   1., 194.,   1.,   1.,
          1.,   1.,   1.,   1.,  83.,   1.,   2.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          2.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   2.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   2.,   1.,   2.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,  72.,  15.,
          1.,  43.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,  14.,   1.,   1.,   1.,   9.,   1.,
         33.,   1., 168.,   1.,   1.,   1.,   7.,   1.,   1.,   1.,   2.,   1.,
         63.,   2.,   1.,   5.,  75.,   1.,  16.,   6.,   1.,   1.,   1.,   1.,
          1.,   1.,   3.,   2.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   2.,
        251.,   1.,   1.,   1.,   1.,   8.,   1.,   3.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   2.,   2.,   1.,   1.,   1.,  11.,   1.,   1.,
          1.,   1.,   1.,   1.])
mr: 5.412576675415039
mrr: 0.9043096899986267
h1: 0.8819018602371216
h3: 0.9156441688537598
h5: 0.9233129024505615
h10: 0.9524539709091187
==================================

Done Testing!
done with training and eval
Experiments took 55 seconds
