['run_exp.py', '0', 'UMLS', '10', '5e-5', 'zscore', '32', '5', '0', '1', 'simple', '1']
loading NN
done loading NN
loading dataset
UMLS
X_p: torch.Size([5216, 37])
X_p: torch.Size([661, 37])
X_p: torch.Size([652, 37])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
loading precalculated corruptions from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 10
Epoch 1 -- batch 0 / 163 loss: 0.1631564497947693
Epoch 2 -- batch 0 / 163 loss: 0.13907821476459503
Epoch 3 -- batch 0 / 163 loss: 0.09419418126344681
Epoch 4 -- batch 0 / 163 loss: 0.10008013248443604
Epoch 5 -- batch 0 / 163 loss: 0.0979500338435173
NOT Saving checkpoint at epoch 5
Epoch 6 -- batch 0 / 163 loss: 0.1294407844543457
Epoch 7 -- batch 0 / 163 loss: 0.09692229330539703
Epoch 8 -- batch 0 / 163 loss: 0.11291462182998657
Epoch 9 -- batch 0 / 163 loss: 0.10365696251392365
Epoch 10 -- batch 0 / 163 loss: 0.12021570652723312
NOT Saving checkpoint at epoch 10
Done Training!

==================================
Testing (cite this): dataloader for dataset UMLS
Testing (cite this): batch 0 / 21
ranks: tensor([180., 230.,  94., 147.,  64.,   1.,   1.,   1.,  10.,  48.,  48.,  27.,
         13., 117., 125., 108., 188.,  21.,  22., 203., 254., 168., 116.,  17.,
        209., 158.,  84.,  11.,  88.,   1.,   1.,   1., 250., 140., 240., 128.,
        244., 241., 250., 166., 232., 232., 234., 235., 232., 138., 239., 241.,
        255.,  65.,  60.,  12., 226.,  23., 239., 242., 241.,   6.,  19.,  14.,
        243.,  99., 239., 242., 242., 222., 226., 201., 216.,  93., 130., 208.,
        113.,   6.,   1.,   2.,   2., 180., 203., 211.,   4.,  28.,  13., 140.,
        216.,  96.,  18., 191., 127.,  63.,  43.,   1.,   1.,  48., 127.,  30.,
        233., 241., 241., 239., 208., 237., 244., 241., 240., 245., 250., 253.,
        192., 246., 120.,  97., 202., 236., 243., 226., 246., 255., 252., 257.,
        247., 244.,  30., 148., 243.,   9.,  10.,   8.,  12.,  17., 188., 103.,
          9.,   1.,   7.,  30., 129., 159., 248., 258., 250.,   4., 201., 199.,
          2.,   2.,   1.,  71., 190., 182., 212., 184., 207.,   2., 179., 167.,
        106.,  83., 109.,  26., 120., 223., 121.,  68., 220., 168.,  95.,   1.,
         22.,  22., 231., 229.,  26., 166., 153.,  46., 174., 152.,  24.,  13.,
         19.,   3.,  46.,   9.,   1.,   5., 249., 125.,   1.,  11.,   1.,   1.,
        243., 192.,  37., 219.,   1.,   1.,  16., 130.,  37.,  95.,  45., 133.,
          9., 186.,  74., 230.,   7.,   8., 193., 198., 179., 197., 184., 175.,
          1., 139., 128., 120., 119., 230.,  10.,   1., 135., 215., 225., 244.,
        229., 153., 151.,  22., 129., 243., 128.,  32., 244., 138., 242., 232.,
        241., 241., 123., 101.,  21., 135., 237., 231., 237., 246., 233., 255.,
        255., 255.,  70.,   1., 225., 188., 234.,  52., 243., 238., 243.,  23.,
        102., 235., 227., 217., 243., 233., 224., 223.,  41.,   1., 219.,  38.,
         51.,  23.,   4.,   2.,   7.,  37.,  64.,   1.,  22.,  53.,  62.,  32.,
        236.,   1.,  24., 135.,  92., 134., 118., 256., 234., 225.,  18.,  18.,
         22., 231.,  34.,   7., 239., 233., 235., 233., 225.,  80., 194., 106.,
         81., 236., 236., 212.,   1.,  15., 179.,   1.,   1., 252., 202., 135.,
         11.,   5.,  13.,  66., 212., 177., 207., 202., 102., 197., 121., 169.,
        176., 228.,  94., 223., 194., 236., 109., 187.,  52., 147., 140., 233.,
        222.,  99.,   1.,   1., 158., 169., 253., 254., 251., 224., 198., 238.,
        214., 206., 205., 217., 185., 217., 180., 127., 219.,   7.,  23.,   1.,
         17.,  18.,   7.,   1., 241.,  47.,  64.,   6.,  22.,  33., 135.,   1.,
        260., 251., 260., 248., 233., 175., 255., 249., 249., 250., 218.,  38.,
        161., 192.,   1., 130., 129.,  55.,  96., 159., 114., 111., 209.,  26.,
          1.,  18.,  21.,  20.,  26.,  22., 134.,   1.,  18.,  96.,   1., 244.,
        226.,  75.,  30.,  23.,  12., 251.,  22., 109., 255., 256., 147., 247.,
        246., 244., 255.,   9., 255.,   1., 177.,  24., 134., 255.,  78., 216.,
        199., 128.,   1.,   3., 191.,  18., 191.,   9., 220., 207.,  21.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   2., 129., 103.,   1.,   7.,
         70., 105.,  12., 204., 206.,  10.,  72.,  92.,  85., 108.,   1.,   1.,
        223., 212., 219., 220., 139., 170., 208.,   1., 210., 196.,   6.,  83.,
        197.,  85., 192., 204., 143., 220., 241., 236., 243.,  21.,  89., 237.,
        144., 215., 207., 223.,   2., 153., 187.,  18.,  16.,  77.,  88.,   7.,
        189., 136., 126.,  16., 105., 173., 140.,   8., 189., 204.,  22.,  67.,
         12.,   3.,   1.,   1.,   1., 229., 205., 177., 174., 135., 129., 121.,
        225., 230.,   1.,   1.,  87., 221.,  38., 184., 203., 237., 227., 242.,
         67., 232., 234., 200., 216., 244., 246., 246., 206., 241., 173., 153.,
        244., 246., 242.,  76.,  66.,  88., 233., 101.,  49.,  79.,   7.,  37.,
        114., 172.,  96.,  88., 169.,   3.,  37.,  40., 203., 168., 188.,  32.,
          3.,   1., 132., 187., 161.,   1.,   2.,  80., 110.,  75.,  13.,  69.,
        167., 207.,  39., 206.,   1.,   1.,   1.,   1.,  18.,  54.,  28., 192.,
        254., 146.,   1.,  13.,  15., 135., 252., 253.,  11.,   9., 197., 198.,
          1.,   1., 160.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   5.,
          1.,  32.,   1.,   1.,   2., 100., 241., 148.,  22., 248., 221.,  66.,
        100., 128.,  71.,  29.])
mr: 123.91104125976562
mrr: 0.14414197206497192
h1: 0.1150306761264801
h3: 0.1380368024110794
h5: 0.14723926782608032
h10: 0.18865031003952026
==================================

Done Testing!
done with training and eval
Experiments took 61 seconds
