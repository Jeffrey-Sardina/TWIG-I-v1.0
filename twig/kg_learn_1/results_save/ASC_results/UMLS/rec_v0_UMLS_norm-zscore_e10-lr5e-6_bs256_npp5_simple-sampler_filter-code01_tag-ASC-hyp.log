['run_exp.py', '0', 'UMLS', '10', '5e-6', 'zscore', '256', '5', '0', '1', 'simple', '1']
loading NN
done loading NN
loading dataset
UMLS
X_p: torch.Size([5216, 37])
X_p: torch.Size([661, 37])
X_p: torch.Size([652, 37])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
loading precalculated corruptions from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 10
Epoch 1 -- batch 0 / 21 loss: 0.13268791139125824
Epoch 2 -- batch 0 / 21 loss: 0.12299375981092453
Epoch 3 -- batch 0 / 21 loss: 0.1449344903230667
Epoch 4 -- batch 0 / 21 loss: 0.1437976360321045
Epoch 5 -- batch 0 / 21 loss: 0.13212965428829193
NOT Saving checkpoint at epoch 5
Epoch 6 -- batch 0 / 21 loss: 0.13473334908485413
Epoch 7 -- batch 0 / 21 loss: 0.12516827881336212
Epoch 8 -- batch 0 / 21 loss: 0.13003896176815033
Epoch 9 -- batch 0 / 21 loss: 0.14390777051448822
Epoch 10 -- batch 0 / 21 loss: 0.12523216009140015
NOT Saving checkpoint at epoch 10
Done Training!

==================================
Testing (cite this): dataloader for dataset UMLS
Testing (cite this): batch 0 / 3
ranks: tensor([184., 230., 172., 202., 183.,  10.,  19.,  31., 103., 165., 156., 120.,
        129., 198., 187., 185., 230.,  64., 207., 231., 254., 127.,  97.,  58.,
         58., 164.,  83.,  92., 123., 247., 239., 249., 250.,  22., 227., 129.,
        250., 248., 246., 241., 226., 225., 232., 231., 231.,  33., 243., 242.,
        255.,  74.,  89.,  17., 235.,  17., 235., 243., 236.,  15.,  18.,  15.,
        243., 233., 208., 229., 214., 222., 225., 217., 220., 154., 151., 186.,
        202.,  29.,   1.,   9.,   1., 128., 203., 201.,   5.,  34.,  83., 140.,
        213.,  72.,  26., 207., 134., 128., 242., 264., 259.,  24., 164.,  67.,
        240., 242., 216.,  88., 143., 236., 129., 118., 218., 219., 250., 253.,
         84., 257., 230.,  29.,  72.,  14.,  15.,  14.,  28., 250., 231., 252.,
        111., 242.,  91., 200., 248.,  28.,  29., 149., 114.,  65., 222., 210.,
        197.,  37., 159., 205., 128., 217., 246., 258., 244., 186., 156., 148.,
          1.,   1.,   1.,  23., 198., 212., 211., 202., 207.,  78., 165.,  48.,
          5.,   1.,   1., 130.,  83., 223., 119., 109., 212., 186., 191.,   9.,
        101.,  90., 231., 229.,  59., 133.,  58.,  19.,  93., 181.,  17.,  11.,
         10.,  44.,  13., 103.,  11., 220., 122., 134.,  12.,  40., 268., 215.,
        254., 243., 195., 229.,   1.,   5., 211., 159., 227., 187., 141., 135.,
        131., 224., 133., 230.,  24.,   8., 226., 198., 188., 179.,  88., 187.,
          1., 118.,  13.,  15., 147., 230., 168., 182., 199., 232., 231., 241.,
        235.,  76., 111.,   3.,  16., 248., 215., 240., 164., 137.,   1.,   1.,
          1., 243.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1., 233., 154., 159.,  69., 242., 235., 243., 202.,
         40., 221., 184., 117., 243., 218., 219., 223., 204.,   5., 219., 104.,
         81.,  28.,  57.,   9.,  78.,  43.,  96.,   8.,  89.,  81., 122.,  54.,
        233.,   3.,  26., 135., 209., 236., 239., 256., 235., 222.,  86.,  37.,
         37., 234., 205.,  21., 238., 231., 234., 234., 241., 241., 233., 176.,
         28., 230., 226., 200.,   7.,  29., 143., 253., 160., 252., 203., 135.,
         90.,   6.,  12.,  90., 211., 183., 204., 126.,  99., 210., 151.,  68.,
        172., 221., 107., 222., 198., 234.,  95., 142.,  59., 153., 155., 231.,
        225., 147., 195., 201., 218., 125., 214., 195., 229., 207., 204., 206.,
        207., 161., 240.,  38.,  30.,  31.,  32.,  30., 100.,   1.,  36.,   8.,
          5.,  23.,   6.,   1., 240., 246., 132., 113., 231.,   1., 130., 178.,
        215., 114., 259., 195., 134., 121., 255., 112., 192.,  62.,  27.,  32.,
        139., 204., 120., 119., 121.,   6.,  10., 203., 129., 175., 213., 227.,
        197., 207., 216., 171., 221., 211., 244., 235.,  18., 125.,  10., 252.,
        134.,  19., 135., 205., 169., 186.,  95., 127., 256., 256., 199., 242.,
        250., 244., 256.,   1., 256.,   1., 182., 127., 135., 255., 127., 186.,
        166., 197.,   9.,   6., 191.,  23., 191., 189., 223., 223., 155.,   4.,
         25.,   5.,  11.,  15.,  29.,   6., 106., 133., 217., 161., 137., 154.,
         82.,  74.,  37., 181.,  99.,  68.,  13.,   1.,   1.,   9., 189., 193.,
        209., 198., 185., 197., 161.,  15., 206.,   1., 207., 205., 126.,  41.,
        204., 127., 206., 147., 128., 218.,  54.,   1.,   1.,   1.,   1.,   1.,
          1., 222., 209., 226.,  16., 215., 212.,  74.,  85., 102.,  75., 131.,
        145., 131., 114.,  20., 123., 157., 185., 182., 190., 212., 161., 176.,
        126., 135.,   1.,   1.,   1., 240., 215., 194., 196., 185., 149., 118.,
        227., 225., 221., 222., 101., 217.,  16.,  11., 115., 237., 202., 239.,
         32., 229., 235., 203., 226., 237., 246., 246., 199., 241., 158.,  92.,
        226., 246., 236.,  28.,  68., 198., 237., 197.,  11.,  22.,  37., 137.,
        156.,  28., 130., 108., 169.,  78., 103.,  84., 192., 115., 176., 176.,
         20.,   7., 173., 203., 178.,   1.,   1., 198., 108., 114., 100.,  96.,
        122.,  92., 116., 230.,   1.,  14., 213.,  41.,  21., 208., 176., 238.,
        254., 150.,  11.,   7.,  80., 135., 250., 253.,  14.,  17., 251., 249.,
          1., 129., 152., 133., 199.,  15.,   6.,   2.,   1.,   1.,   1.,   1.,
         43.,  95.,   1.,   1.,  23., 124., 152.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.])
mr: 133.5797576904297
mrr: 0.11437112092971802
h1: 0.09509202092885971
h3: 0.09969325363636017
h5: 0.11042945086956024
h10: 0.14263804256916046
==================================

Done Testing!
done with training and eval
Experiments took 38 seconds
