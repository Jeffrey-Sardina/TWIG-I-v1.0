['run_exp.py', '0', 'UMLS', '10', '5e-6', 'zscore', '32', '30', '0', '1', 'simple', '1']
loading NN
done loading NN
loading dataset
UMLS
X_p: torch.Size([5216, 37])
X_p: torch.Size([661, 37])
X_p: torch.Size([652, 37])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
loading precalculated corruptions from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 10
Epoch 1 -- batch 0 / 163 loss: 0.17566923797130585
Epoch 2 -- batch 0 / 163 loss: 0.14887966215610504
Epoch 3 -- batch 0 / 163 loss: 0.12315498292446136
Epoch 4 -- batch 0 / 163 loss: 0.12880219519138336
Epoch 5 -- batch 0 / 163 loss: 0.12404464930295944
NOT Saving checkpoint at epoch 5
Epoch 6 -- batch 0 / 163 loss: 0.15284571051597595
Epoch 7 -- batch 0 / 163 loss: 0.11874093860387802
Epoch 8 -- batch 0 / 163 loss: 0.1445118635892868
Epoch 9 -- batch 0 / 163 loss: 0.1495714634656906
Epoch 10 -- batch 0 / 163 loss: 0.15927650034427643
NOT Saving checkpoint at epoch 10
Done Training!

==================================
Testing (cite this): dataloader for dataset UMLS
Testing (cite this): batch 0 / 21
ranks: tensor([195., 230., 181., 207., 166.,   1.,   1.,   4.,  67.,  83.,  84.,  67.,
         63., 186., 185., 189., 220.,  52., 190., 235., 255., 136.,  81.,  34.,
         52., 164.,  88.,  79., 110.,   1.,   1.,   1., 250., 126., 230., 124.,
        244., 241., 249., 241., 230., 225., 230., 233., 227., 129., 238., 243.,
        255., 199., 183.,  25., 239.,  12., 235., 243., 241.,  17.,  21.,  17.,
        243., 229., 235., 242., 241., 219., 223., 209., 215., 119., 184., 206.,
        117.,  21.,   1.,  36.,   5., 175., 203., 208.,  13.,  56.,  54., 130.,
        211.,  33.,  44., 197., 122.,  69.,  89.,   1.,   1.,  96., 134.,  29.,
        199., 240., 240., 231., 239., 247., 245., 240., 244., 244., 250., 253.,
         38., 252., 105., 105., 146., 155., 228., 199., 218., 255., 253., 257.,
        247., 245.,  73., 193., 245.,  25.,  27.,  16.,  23.,  67., 215., 195.,
         58.,   8.,  16., 155., 128., 225., 252., 258., 252.,  20., 193., 193.,
          1.,   1.,   1.,  31., 197., 207., 212., 204., 207., 147., 174., 125.,
        110.,  78.,  99.,  33., 134., 223., 116., 185., 201., 192., 143.,   8.,
        146.,  56., 231., 229., 141., 203., 171.,  46., 206., 189.,  23.,  17.,
         27.,   6.,  78.,  76.,   1.,  90., 252., 124.,   2.,  19.,   1.,   1.,
        245., 222., 192., 215.,   1.,   1., 100., 145., 179., 149., 143., 134.,
         89., 224., 124., 230.,   8.,   1., 224., 198., 189., 182., 171., 184.,
          1.,  86.,  57.,  88., 181., 230.,  42.,   1., 172., 223., 234., 234.,
        211., 162., 154.,   9., 111., 241., 148., 205., 235., 163., 236., 234.,
        245., 243., 134., 151.,  75., 213., 238., 233., 237., 246., 234., 255.,
        255., 255.,  70.,   1., 239., 204., 213.,  69., 242., 230., 243., 197.,
         86., 229., 181., 124., 243., 224., 222., 223., 206.,   3., 215., 116.,
        130.,  30.,  63.,   6.,  99.,  38.,  86.,   4.,  77.,  81.,  93.,  54.,
        236.,   5.,  67., 135., 200., 230., 230., 256., 228., 234.,  82.,  37.,
         33., 238., 214.,  22., 237., 237., 237., 239., 232., 237., 240., 197.,
         32., 225., 228., 207.,   8., 180., 166.,   1.,  29., 252., 165., 135.,
         25.,   6.,  11., 165., 212., 193., 207., 200., 145., 203., 167.,  88.,
        174., 226., 128., 223., 198., 236.,  79., 141.,  98., 192., 178., 234.,
        214., 126.,   1.,   1., 184., 190., 247., 245., 244., 170., 191., 223.,
        182., 181., 233., 204., 200., 205., 207., 102., 201.,   4.,  35.,   9.,
         22.,  20.,  11.,   1., 240.,  33.,  93.,   8.,  26.,  21., 135.,   1.,
        259., 242., 260., 250., 239., 206., 255., 239., 249., 249., 215.,  70.,
        163., 190.,   1., 135., 130.,  65., 112., 183., 169., 176., 214., 199.,
         33.,  83., 157.,  73., 193., 185., 136.,   1.,  36.,  91.,   1., 246.,
        229., 204.,  80., 167., 146., 209.,  97., 180., 255., 256., 172., 238.,
        248., 244., 255.,  15., 252.,   1., 178.,  89., 134., 255.,  54., 208.,
        173.,  79.,   1.,   1., 191.,   1., 192., 143., 223., 223., 146.,   1.,
          1.,   1.,   1.,   1.,   3.,   1.,  42.,  26., 140., 102.,  14., 127.,
        112., 127., 166., 203., 206.,  18., 101., 109., 103., 118.,   1.,   1.,
        209., 203., 200., 201., 151., 124., 209.,   1., 205., 197.,  19., 110.,
        195., 116., 204., 191., 139., 214., 241., 223., 243.,  31.,  96., 216.,
        161., 209., 189., 221.,   3., 158., 209.,  45.,  47., 102.,  69., 142.,
        192., 124., 109.,  13., 118., 136., 161., 169., 193., 209., 152., 170.,
        121.,  88.,   1.,   1.,   1., 235., 203., 181., 187., 181., 173., 112.,
        229., 233.,   1.,   1., 101., 212.,  85.,  99., 105., 237., 217., 241.,
         82., 229., 225., 186., 217., 227., 246., 246., 147., 243., 197., 151.,
        245., 246., 242.,  92.,  39., 198., 235., 198.,  28., 123.,   4., 110.,
         36.,  53., 112.,  68., 169.,  14.,  25., 139., 204., 179., 197., 134.,
          1.,   1., 128., 200., 185.,   1.,   9., 187., 120.,  66.,  13.,  93.,
        167., 196.,  49., 229.,   1.,   1.,   1.,   1.,  28.,  30.,  55., 194.,
        254., 144.,   1.,  14.,  21., 135., 245., 253.,   1.,   1., 206., 209.,
          4.,   1., 142.,  62.,  24.,   4.,   1.,   1., 114., 129.,   1.,  26.,
          5.,  31.,   1.,   1.,  38.,  90., 241., 127.,  22., 248., 222., 109.,
        125., 171., 116.,  28.])
mr: 138.70706176757812
mrr: 0.1125800684094429
h1: 0.09509202092885971
h3: 0.10122699290513992
h5: 0.1150306761264801
h10: 0.1319018453359604
==================================

Done Testing!
done with training and eval
Experiments took 47 seconds
