['run_exp.py', '0', 'UMLS', '10', '5e-4', 'zscore', '1024', '30', '0', '1', 'simple', '1']
loading NN
done loading NN
loading dataset
UMLS
X_p: torch.Size([5216, 37])
X_p: torch.Size([661, 37])
X_p: torch.Size([652, 37])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
loading precalculated corruptions from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 10
Epoch 1 -- batch 0 / 6 loss: 0.13135282695293427
Epoch 2 -- batch 0 / 6 loss: 0.12973923981189728
Epoch 3 -- batch 0 / 6 loss: 0.12084782123565674
Epoch 4 -- batch 0 / 6 loss: 0.1207863986492157
Epoch 5 -- batch 0 / 6 loss: 0.12691473960876465
NOT Saving checkpoint at epoch 5
Epoch 6 -- batch 0 / 6 loss: 0.11589939147233963
Epoch 7 -- batch 0 / 6 loss: 0.11816389858722687
Epoch 8 -- batch 0 / 6 loss: 0.1156812533736229
Epoch 9 -- batch 0 / 6 loss: 0.113405741751194
Epoch 10 -- batch 0 / 6 loss: 0.11192542314529419
NOT Saving checkpoint at epoch 10
Done Training!

==================================
Testing (cite this): dataloader for dataset UMLS
Testing (cite this): batch 0 / 1
ranks: tensor([180., 230.,  87., 142.,  40.,   1.,   1.,   1.,   9.,  31.,  29.,  28.,
          8., 111., 121.,  83., 175.,  25.,  57., 223., 251., 164., 108.,  19.,
        119., 160.,  65.,   4.,  73., 247., 242., 249., 250.,  24., 239., 117.,
        249., 243., 249., 211., 229., 230., 231., 232., 234., 102., 243., 241.,
        255.,  19.,  21.,   4., 217.,  13., 230., 242., 240.,   5.,  16.,  15.,
        243., 173., 235., 234., 237., 222., 226., 212., 219., 113.,  50., 208.,
        200.,   4.,   1.,   3.,   1., 140., 203., 195.,   1.,  14.,  34., 137.,
        215., 144.,  14., 204., 134., 131., 239., 263., 256.,  25., 162., 113.,
        242., 241., 231., 120.,  56., 190., 205., 146., 188., 242., 250., 253.,
        236., 257., 237.,  28., 153.,  22.,  21.,  21.,  38., 246., 226., 254.,
        132., 236.,  31., 141., 240.,  12.,   8.,  92.,  29.,  20., 202., 221.,
         23.,  22., 148., 111., 127.,  10., 199., 258., 247., 110., 199., 198.,
          1.,   1.,   1.,  83., 200., 211., 212., 198., 207.,  14.,  76.,  11.,
          1.,   1.,   1., 127.,   5., 223., 154., 132., 229., 202., 104.,   1.,
         14.,  79., 231., 229.,  22., 139., 128.,  19.,  18., 165.,   4.,  13.,
          2.,  55.,   5.,  81.,  10., 138.,  10.,  22.,   9.,  22., 254., 180.,
        223., 138.,  90., 188.,   1.,   1.,  16., 159.,  89., 168.,  96., 135.,
        132., 207.,  63., 230.,   1.,  10., 178., 198., 180., 176., 180., 169.,
          1.,  67.,  91.,  16., 140., 230.,  22.,  53., 122., 241., 242., 243.,
        248., 258.,  63.,  10., 102., 249.,  52., 196., 250., 179., 246., 242.,
        235., 243.,  18.,  23.,   8.,  24., 237., 188., 236., 246., 188., 247.,
        164., 213., 197.,  92.,  52., 134., 105.,  32., 237., 230., 243.,  45.,
         42.,  31.,  87., 118., 243., 121., 222., 223., 160.,   1., 222., 150.,
        213.,  54.,  21.,  41., 168., 200.,  34.,   1.,  20.,  73.,  21.,  93.,
        236.,   1., 188., 135.,  57., 108.,  24., 253., 243., 206.,  10.,   1.,
          1., 174.,  19.,   1., 231., 198., 178., 171., 161.,  19., 223., 228.,
        225., 238., 241., 240., 103., 170., 241., 253., 106., 252., 207., 135.,
         21.,  16.,  67., 176., 212., 192., 207., 196.,  24., 155.,   3.,  90.,
        191., 228.,   5., 223., 233., 236.,  79., 204., 108.,  77., 178., 236.,
        233., 213., 214., 139., 202.,  89.,  32.,  38., 137., 106.,  37., 212.,
        239., 239., 236., 236., 236., 239., 236., 231., 232., 124., 233.,  11.,
        189., 209., 133.,  15., 241., 126., 100.,  94., 229.,   1., 123., 250.,
        251.,  57., 260., 179.,  55.,  18., 255., 157., 153., 189., 137., 174.,
         12., 232.,  80., 105., 118., 129., 103., 184.,  13.,  23., 156., 173.,
          1., 146., 144.,  20.,  21., 152., 246., 120., 103., 133.,   1., 199.,
        164.,   7.,   8., 155., 208., 230.,   6.,   9., 254., 256., 184., 243.,
        246., 236., 252.,   2., 256.,   7., 195., 107., 135., 255., 157., 199.,
        213., 213.,  32.,  28., 191.,  21., 190., 176., 223., 221., 191.,  47.,
          4.,   1.,  68.,   3., 116.,  30.,   1.,   1., 129., 192.,  22.,  67.,
        110., 132.,  16., 126., 155.,   1.,  18.,   3.,  10.,  14.,  63., 209.,
        220., 217., 218., 216., 136.,  60., 216.,  17., 210., 190.,   8.,   5.,
        183.,  11., 204., 210., 133., 222., 235., 101., 243.,   1.,   2., 164.,
        130., 218., 223., 226.,   8., 225., 217., 111., 204.,  24., 108.,  94.,
        135., 115., 196.,  48.,  46., 198.,  84.,   5., 203., 204.,  22.,  64.,
        103.,  69.,   1.,   1.,   2., 216., 136.,  51.,  92.,  19.,  67.,   2.,
        222., 230., 208., 176.,  10., 220.,  36., 199.,  45., 237., 235., 240.,
          7., 198., 114.,  82.,  62., 208., 246., 246.,  59., 209., 173., 156.,
        230., 246., 232.,   5.,  21., 108., 231., 183., 142., 103., 152.,  14.,
        134., 217., 127., 111., 169.,   1., 118.,  59., 208., 201., 182., 188.,
          1.,   1., 210., 203., 164.,  14.,  64., 141.,   4.,   2.,  52.,   5.,
         71.,  21.,  14.,  79.,   9.,  74., 104., 127., 176., 134.,   1., 194.,
          1., 154., 101.,  24., 124., 135.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1., 149.,   1.,  47.,   1.,  45.,  40.,   1.,   1.,   1.,   1.,
        100.,  40.,   1.,   1.,  11., 123.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.])
mr: 124.09202575683594
mrr: 0.12531664967536926
h1: 0.09815950691699982
h3: 0.11349692940711975
h5: 0.1349693238735199
h10: 0.16871166229248047
==================================

Done Testing!
done with training and eval
Experiments took 40 seconds
