['run_exp.py', '0', 'UMLS', '10', '5e-6', 'zscore', '32', '5', '0', '1', 'simple', '1']
loading NN
done loading NN
loading dataset
UMLS
X_p: torch.Size([5216, 37])
X_p: torch.Size([661, 37])
X_p: torch.Size([652, 37])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
loading precalculated corruptions from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 10
Epoch 1 -- batch 0 / 163 loss: 0.1747109293937683
Epoch 2 -- batch 0 / 163 loss: 0.15000379085540771
Epoch 3 -- batch 0 / 163 loss: 0.1283523142337799
Epoch 4 -- batch 0 / 163 loss: 0.12689898908138275
Epoch 5 -- batch 0 / 163 loss: 0.1273585557937622
NOT Saving checkpoint at epoch 5
Epoch 6 -- batch 0 / 163 loss: 0.16228671371936798
Epoch 7 -- batch 0 / 163 loss: 0.1392306387424469
Epoch 8 -- batch 0 / 163 loss: 0.1388353556394577
Epoch 9 -- batch 0 / 163 loss: 0.14916683733463287
Epoch 10 -- batch 0 / 163 loss: 0.15915489196777344
NOT Saving checkpoint at epoch 10
Done Training!

==================================
Testing (cite this): dataloader for dataset UMLS
Testing (cite this): batch 0 / 21
ranks: tensor([195., 230., 180., 207., 169.,   1.,   1.,   6.,  73., 100., 100.,  64.,
         70., 188., 183., 185., 225.,  40., 195., 236., 255., 134.,  86.,  39.,
         58., 164.,  93.,  77., 111.,   1.,   1.,   1., 250., 126., 229., 126.,
        245., 241., 249., 240., 229., 227., 230., 232., 230., 127., 237., 242.,
        255., 202., 172.,  14., 237.,  23., 236., 243., 241.,  10.,  22.,  17.,
        243., 228., 233., 242., 241., 219., 223., 208., 216., 118., 190., 208.,
        118.,  25.,   1.,  28.,   2., 176., 203., 208.,  11.,  63.,  46., 138.,
        214.,  42.,  39., 187., 123.,  68.,  83.,   1.,   1.,  92., 131.,  33.,
        200., 240., 240., 232., 238., 247., 245., 240., 244., 244., 250., 253.,
         35., 250.,  95., 106., 154., 164., 229., 197., 212., 255., 254., 257.,
        247., 244.,  62., 191., 246.,  26.,  27.,  17.,  23.,  67., 216., 195.,
         56.,   8.,  21., 153., 132., 225., 252., 258., 253.,  22., 193., 193.,
          1.,   1.,   1.,  34., 198., 208., 212., 205., 207., 141., 176., 132.,
        114.,  76., 104.,  24., 134., 223., 117., 180., 211., 196., 143.,   8.,
        149.,  58., 231., 229., 133., 194., 175.,  46., 207., 190.,  25.,  17.,
         27.,   5.,  79.,  67.,   1.,  98., 254., 126.,   3.,  17.,   1.,   1.,
        245., 224., 186., 217.,   1.,   1., 106., 148., 176., 148., 142., 134.,
         97., 225., 120., 230.,  11.,   1., 225., 198., 181., 188., 169., 177.,
          1.,  89.,  62.,  99., 179., 230.,  45.,   1., 174., 226., 229., 234.,
        209., 155., 156.,   7., 106., 241., 144., 203., 235., 161., 237., 233.,
        245., 243., 146., 131.,  81., 217., 239., 233., 239., 246., 239., 255.,
        255., 255.,  70.,   1., 239., 198., 207.,  73., 242., 233., 243., 202.,
         85., 228., 182., 115., 243., 221., 220., 223., 204.,   5., 219., 109.,
        118.,  23.,  75.,   7.,  86.,  33.,  90.,   6.,  79.,  69., 104.,  52.,
        236.,   7.,  62., 135., 200., 228., 230., 256., 234., 228.,  82.,  35.,
         41., 239., 216.,  21., 235., 236., 238., 234., 234., 238., 237., 194.,
         22., 227., 230., 205.,   9., 180., 169.,   1.,  29., 250., 167., 135.,
         22.,   5.,   9., 162., 212., 195., 207., 203., 146., 199., 171.,  70.,
        173., 226., 120., 223., 195., 236.,  80., 133.,  91., 190., 186., 233.,
        213., 122.,   1.,   1., 183., 190., 244., 247., 245., 156., 191., 219.,
        182., 183., 228., 207., 202., 201., 205., 108., 201.,   7.,  32.,   7.,
         16.,  22.,   9.,   1., 240.,  39.,  94.,   6.,  24.,  23., 135.,   1.,
        259., 241., 260., 248., 241., 208., 255., 236., 249., 250., 210.,  71.,
        157., 183.,   1., 134., 130.,  65., 115., 191., 173., 174., 211., 207.,
         33.,  87., 161.,  73., 191., 188., 135.,   1.,  32.,  87.,   1., 246.,
        224., 207.,  90., 174., 146., 214.,  93., 173., 255., 256., 161., 242.,
        246., 244., 255.,  17., 254.,   1., 180.,  89., 135., 255.,  57., 202.,
        173.,  85.,   1.,   1., 191.,   1., 193., 148., 223., 223., 141.,   1.,
          1.,   1.,   1.,   1.,   4.,   1.,  44.,  36., 133., 109.,  16., 131.,
        113., 122., 172., 205., 205.,  15., 108., 107., 101., 118.,   1.,   1.,
        209., 200., 197., 199., 149., 126., 208.,   1., 206., 196.,  20., 112.,
        196., 119., 204., 189., 139., 214., 240., 220., 243.,  32.,  98., 209.,
        153., 211., 164., 222.,   7., 158., 208.,  40.,  54.,  96.,  73., 133.,
        186., 124., 109.,  15., 116., 139., 168., 169., 189., 208., 151., 170.,
        116.,  97.,   1.,   1.,   1., 230., 208., 182., 192., 181., 175., 116.,
        228., 229.,   1.,   1., 101., 213.,  88.,  95., 110., 237., 216., 241.,
         84., 226., 228., 192., 206., 228., 246., 246., 143., 243., 202., 147.,
        244., 246., 241.,  92.,  49., 197., 235., 198.,  28., 119.,   5., 108.,
         36.,  53., 113.,  62., 169.,  14.,  26., 158., 202., 181., 195., 140.,
          1.,   1., 147., 202., 185.,   1.,  11., 192., 122.,  71.,  13.,  93.,
        163., 198.,  48., 229.,   1.,   1.,   1.,   1.,  28.,  29.,  53., 195.,
        254., 146.,   1.,  12.,  17., 135., 248., 253.,   1.,   1., 210., 199.,
          5.,   1., 133.,  70.,  27.,   3.,   1.,   1., 116., 134.,   1.,  26.,
          5.,  32.,   1.,   1.,  37.,  90., 241., 136.,  14., 248., 223., 117.,
        119., 174., 108.,  28.])
mr: 138.68405151367188
mrr: 0.11192045360803604
h1: 0.09509202092885971
h3: 0.09969325363636017
h5: 0.11042945086956024
h10: 0.13343557715415955
==================================

Done Testing!
done with training and eval
Experiments took 42 seconds
