['run_exp.py', '0', 'UMLS', '10', '5e-5', 'zscore', '256', '30', '0', '1', 'simple', '1']
loading NN
done loading NN
loading dataset
UMLS
X_p: torch.Size([5216, 37])
X_p: torch.Size([661, 37])
X_p: torch.Size([652, 37])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
loading precalculated corruptions from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 10
Epoch 1 -- batch 0 / 21 loss: 0.13424617052078247
Epoch 2 -- batch 0 / 21 loss: 0.1258038729429245
Epoch 3 -- batch 0 / 21 loss: 0.14064131677150726
Epoch 4 -- batch 0 / 21 loss: 0.1358560025691986
Epoch 5 -- batch 0 / 21 loss: 0.1257874071598053
NOT Saving checkpoint at epoch 5
Epoch 6 -- batch 0 / 21 loss: 0.12894056737422943
Epoch 7 -- batch 0 / 21 loss: 0.11579959094524384
Epoch 8 -- batch 0 / 21 loss: 0.12018665671348572
Epoch 9 -- batch 0 / 21 loss: 0.12802709639072418
Epoch 10 -- batch 0 / 21 loss: 0.11324437707662582
NOT Saving checkpoint at epoch 10
Done Training!

==================================
Testing (cite this): dataloader for dataset UMLS
Testing (cite this): batch 0 / 3
ranks: tensor([194., 230., 179., 199.,  76.,   1.,   1.,   1.,  44.,  49.,  40.,  26.,
         23., 162., 170., 174., 192.,   9., 162., 238., 255., 162.,  80.,  22.,
        109., 166., 106.,  41., 105., 247., 244., 249., 250.,  23., 237., 132.,
        249., 250., 251., 239., 227., 226., 239., 235., 238.,  47., 243., 243.,
        255., 167., 116.,  19., 237.,  18., 231., 243., 242.,  18.,  19.,  17.,
        243., 226., 236., 234., 236., 222., 222., 219., 220., 131., 162., 212.,
        204.,  27.,   1.,  28.,   1., 102., 203., 213.,   5.,  38.,  79., 121.,
        216., 148.,  65., 215., 135., 134., 241., 264., 259.,  37., 163., 124.,
        240., 241., 217.,  93., 125., 227., 215., 120., 196., 245., 250., 253.,
        226., 257., 248., 104., 146.,  46.,  34.,  26.,  95., 246., 225., 254.,
        200., 223., 163., 192., 239.,  14.,  17., 123., 126.,  45., 209., 222.,
         79.,  31., 159., 199., 125.,  56., 241., 258., 250., 140., 177., 176.,
          1.,   1.,   1.,  29., 200., 215., 212., 199., 207.,  18.,  47.,   5.,
          1.,   1.,   1., 134.,   5., 223., 168., 176., 225., 211., 130.,   1.,
         75.,  58., 231., 229., 172., 154., 142.,  48.,  91., 200.,   1.,   5.,
          1.,  50.,   1., 103.,  12., 207.,  19.,  27.,  11.,  46., 263., 201.,
        247., 205., 156., 209.,   1.,   1.,  85., 160., 145., 179., 148., 135.,
        132., 211.,  83., 230.,   1.,   1., 212., 198., 186., 189., 159., 184.,
          1.,  33.,  16.,  16., 153., 230., 186., 143., 158., 242., 242., 243.,
        243.,  76., 123.,   3.,  93., 249., 185., 245., 165., 149.,   1.,   1.,
          1., 243.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1., 249., 225., 228.,  67., 242., 233., 243., 185.,
        161., 232., 201., 214., 243., 225., 224., 223., 200.,   4., 215., 102.,
        131.,  14.,  44.,   5., 106.,  30.,  69.,   4.,  93.,  64.,  69.,  75.,
        236.,   5.,  32., 135., 224., 239., 240., 256., 235., 235.,  42.,  27.,
         19., 239., 222.,  16., 237., 240., 240., 239., 243., 231., 211., 198.,
         39., 216., 239., 214.,  11.,  99., 148., 253., 147., 252., 199., 135.,
        105.,  11.,  22., 128., 211., 188., 207., 163.,  21., 203., 179., 113.,
        174., 228., 110., 223., 191., 236.,  56., 153., 117., 197., 183., 236.,
        221., 189., 220., 225., 228., 149., 226., 211., 236., 222., 205., 229.,
        216., 108., 239.,  33.,  31.,  55.,  27.,  24.,  91.,   1.,  42.,   8.,
         12.,  14.,  11.,   1., 241., 248., 138., 117., 228.,   1., 131., 195.,
        227., 181., 260., 192., 192., 105., 255., 200., 200., 186.,  73., 129.,
        148., 209., 103., 107., 112.,   1.,   1., 209., 173., 173., 196., 206.,
        174., 194., 194.,   6., 202., 200., 242., 238.,  95., 123.,   1., 251.,
        129.,  19., 132.,  75., 147., 101., 108., 189., 254., 256., 192., 229.,
        238., 245., 252.,   1., 256.,   1., 149., 112., 135., 255.,  83., 196.,
        194., 207.,   7.,   1., 191.,  18., 196., 201., 220., 220., 136.,   1.,
         19.,   1.,   8.,  10.,   1.,   1.,   6.,   6., 188., 157., 125., 148.,
         72.,  71.,  39., 189., 118., 139.,  12.,   7.,   5.,  42., 188., 199.,
        216., 209., 208., 209., 147.,  31., 216.,   2., 198., 191., 108., 101.,
        182., 102., 209., 199., 106., 208.,  42.,   1.,   1.,   1.,   1.,   1.,
          1., 225., 223., 227.,  11., 201., 198.,  54.,  27., 102.,  54., 139.,
        201., 108., 109.,  13.,  94., 115., 101.,  81., 193., 203., 135., 166.,
        104.,   7.,   1.,   1.,   1., 234., 198., 178., 172., 178., 175., 111.,
        226., 234., 232., 231.,  96., 206.,  62.,  27., 181., 237., 228., 242.,
         10., 226., 234., 210., 233., 237., 246., 246., 206., 240., 172.,  73.,
        234., 246., 240.,  92.,  92., 193., 237., 194.,  24.,  34.,  28.,  74.,
        168., 116., 130., 104., 169.,   2., 112.,  49., 210., 144., 201., 158.,
         31.,  17.,  42., 176., 178.,   1.,   1., 165., 112., 119., 104.,  74.,
        117.,  77., 117., 228.,   1.,   1., 193.,  52.,  21., 236., 185., 242.,
        254., 144.,   1.,   1.,  76., 135., 238., 253.,  95.,  79., 251., 249.,
          1., 131., 141.,  34., 194.,  46.,   7.,   9.,   1.,   1.,   1.,   1.,
         39., 112.,   1.,   1.,   7.,  65., 152.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.])
mr: 132.5858917236328
mrr: 0.1420697271823883
h1: 0.12423312664031982
h3: 0.12883435189723969
h5: 0.14263804256916046
h10: 0.16411042213439941
==================================

Done Testing!
done with training and eval
Experiments took 40 seconds
