['run_exp.py', '0', 'UMLS', '10', '5e-5', 'zscore', '1024', '100', '0', '1', 'simple', '1']
loading NN
done loading NN
loading dataset
UMLS
X_p: torch.Size([5216, 37])
X_p: torch.Size([661, 37])
X_p: torch.Size([652, 37])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
loading precalculated corruptions from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 10
Epoch 1 -- batch 0 / 6 loss: 0.1323539912700653
Epoch 2 -- batch 0 / 6 loss: 0.13245685398578644
Epoch 3 -- batch 0 / 6 loss: 0.1303834766149521
Epoch 4 -- batch 0 / 6 loss: 0.13037435710430145
Epoch 5 -- batch 0 / 6 loss: 0.13850677013397217
NOT Saving checkpoint at epoch 5
Epoch 6 -- batch 0 / 6 loss: 0.13228602707386017
Epoch 7 -- batch 0 / 6 loss: 0.12479207664728165
Epoch 8 -- batch 0 / 6 loss: 0.1270667463541031
Epoch 9 -- batch 0 / 6 loss: 0.12535561621189117
Epoch 10 -- batch 0 / 6 loss: 0.13162130117416382
NOT Saving checkpoint at epoch 10
Done Training!

==================================
Testing (cite this): dataloader for dataset UMLS
Testing (cite this): batch 0 / 1
ranks: tensor([194., 230., 179., 207., 168.,   1.,   1.,   5.,  82.,  98.,  98.,  66.,
         74., 184., 183., 178., 224.,  53., 191., 233., 254., 129.,  81.,  44.,
         54., 165.,  85.,  84., 111., 241., 240., 249., 250.,  15., 232., 127.,
        248., 247., 248., 241., 232., 218., 230., 232., 232.,  35., 240., 243.,
        255.,  96.,  75.,  12., 236.,  18., 235., 243., 237.,  14.,  17.,  19.,
        243., 232., 220., 231., 228., 222., 225., 219., 220., 148., 176., 198.,
        207.,  21.,   2.,  28.,   1., 108., 203., 210.,   6.,  33.,  84., 130.,
        215.,  81.,  29., 210., 135., 131., 242., 264., 259.,  26., 167.,  74.,
        239., 240., 211.,  95., 132., 231., 147., 121., 213., 227., 250., 253.,
        110., 257., 238.,  37., 112.,  21.,  25.,  20.,  30., 244., 238., 249.,
        201., 233.,  93., 188., 245.,  25.,  26., 145., 101.,  52., 216., 216.,
        149.,  35., 161., 205., 130., 188., 245., 258., 246., 173., 165., 165.,
          1.,   1.,   1.,  29., 197., 213., 211., 197., 207.,  80.,  87.,   9.,
          1.,   1.,   1., 146.,  23., 223., 122., 172., 206., 199., 162.,  12.,
        113.,  79., 231., 229.,  92., 134., 115.,  23.,  88., 203.,  18.,  12.,
          2.,  63.,  12.,  97.,   6., 212.,  83.,  83.,   9.,  38., 268., 209.,
        254., 234., 188., 225.,   1.,   1., 191., 158., 207., 187., 142., 135.,
        131., 222., 118., 230.,  10.,   1., 223., 198., 192., 181., 103., 192.,
          1.,  78.,  14.,  18., 152., 230., 169., 185., 182., 239., 237., 237.,
        238., 258., 130.,   1.,  32., 249., 202., 245., 248., 232., 244., 243.,
        244., 243.,  88.,  93.,  12., 195., 238., 228., 237., 246., 231., 244.,
        165., 210., 154., 101.,  79., 144., 106.,  10., 233., 165., 243.,  90.,
         26.,  17.,  21.,  99., 243.,  67., 221., 223., 220.,   6., 223., 212.,
        215.,  53., 153.,  27., 191., 195.,  58.,   5., 115.,  87.,  20., 120.,
        236.,   1., 181., 135.,  84., 187., 192., 256., 243., 213.,  10.,   3.,
          2., 204.,  57.,   1., 214., 206., 179., 156., 180., 184., 244., 202.,
        198., 230., 241., 228., 124., 204., 208., 253., 144., 252., 202., 135.,
         31.,  28., 124., 200., 212., 191., 207., 204., 180., 211.,  44.,  12.,
        167., 226.,  13., 223., 233., 236.,  56., 181., 144., 128., 218., 236.,
        232., 194., 193., 114., 191.,  90.,  23.,  32.,  35.,  38.,  34., 161.,
        235., 236., 243., 233., 217., 212., 215., 201., 235., 129., 223.,   1.,
         69., 189., 161.,  10., 241.,  44.,  92.,  92., 220.,   1., 134., 254.,
        242.,  65., 260., 176., 190.,  52., 255., 152., 121., 177., 185., 184.,
         30., 161., 121., 125., 126., 190., 152., 219.,  41.,  54., 186., 206.,
         50., 210., 215., 132.,  84., 223., 248., 204., 162., 133.,   1., 206.,
        213.,  16.,  15., 187., 206., 154.,   1.,  33., 249., 256., 214., 229.,
        228., 245., 253.,   5., 256.,  14., 232., 133., 135., 255.,  26., 168.,
        170., 187.,  23.,  16., 191.,   6., 192., 195., 222., 223., 191., 101.,
          7.,   1., 115.,   2., 139.,  38.,  52.,  37., 205., 209., 106., 127.,
        119., 128., 169., 195., 212.,  25.,  37.,   7.,   9.,  24., 103., 199.,
        211., 200., 195., 199., 160.,  14., 206.,  12., 205., 196.,  22.,  13.,
        194.,  20., 203., 185., 140., 215., 237., 192., 243.,   1.,   8., 201.,
        217., 219., 210., 226.,  25., 221., 218., 176., 210., 110.,  89., 140.,
        111.,  94., 122.,  38.,  13., 167.,  55., 161., 186., 208., 146., 158.,
        162., 126.,   1.,   5.,   6., 229., 209., 190., 154., 192.,  93.,   5.,
        229., 228., 210., 203.,  13., 214.,  67.,  26.,   7., 237., 231., 233.,
         11., 217., 225., 178., 182., 197., 246., 246.,  33., 219., 161., 116.,
        226., 246., 236.,  12.,  19., 198., 232., 194.,  55., 146., 133.,  26.,
          8., 163., 123.,  59., 169.,   1., 111., 165., 194., 185., 195., 166.,
          2.,   1., 175., 201., 187.,  19.,  85., 191.,  13.,   8.,  51.,   6.,
         76.,  27.,  12., 143.,  22.,  68., 133., 156., 204., 124.,   1., 159.,
          1., 153.,  97.,  36., 117., 135.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1., 150.,   1., 128.,   1.,  73.,  51.,   1.,   1.,   1.,   1.,
        142.,  72.,   1.,   1.,  26., 106.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.])
mr: 136.440185546875
mrr: 0.10225210338830948
h1: 0.08128834515810013
h3: 0.09049079567193985
h5: 0.09815950691699982
h10: 0.12730062007904053
==================================

Done Testing!
done with training and eval
Experiments took 46 seconds
