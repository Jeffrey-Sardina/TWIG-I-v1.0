['run_exp.py', '0', 'UMLS', '10', '5e-5', 'zscore', '256', '5', '0', '1', 'simple', '1']
loading NN
done loading NN
loading dataset
UMLS
X_p: torch.Size([5216, 37])
X_p: torch.Size([661, 37])
X_p: torch.Size([652, 37])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
loading precalculated corruptions from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 10
Epoch 1 -- batch 0 / 21 loss: 0.13787975907325745
Epoch 2 -- batch 0 / 21 loss: 0.1216202974319458
Epoch 3 -- batch 0 / 21 loss: 0.14223246276378632
Epoch 4 -- batch 0 / 21 loss: 0.13639317452907562
Epoch 5 -- batch 0 / 21 loss: 0.12847024202346802
NOT Saving checkpoint at epoch 5
Epoch 6 -- batch 0 / 21 loss: 0.13030840456485748
Epoch 7 -- batch 0 / 21 loss: 0.11117728054523468
Epoch 8 -- batch 0 / 21 loss: 0.1224633976817131
Epoch 9 -- batch 0 / 21 loss: 0.12170249223709106
Epoch 10 -- batch 0 / 21 loss: 0.11549156159162521
NOT Saving checkpoint at epoch 10
Done Training!

==================================
Testing (cite this): dataloader for dataset UMLS
Testing (cite this): batch 0 / 3
ranks: tensor([195., 230., 179., 199.,  75.,   1.,   1.,   1.,  43.,  42.,  42.,  23.,
         22., 165., 164., 173., 195.,   5., 169., 239., 255., 160.,  85.,  28.,
        114., 165., 114.,  50., 103., 249., 244., 249., 250.,  24., 236., 126.,
        250., 250., 251., 240., 224., 228., 240., 236., 238.,  45., 243., 243.,
        255., 173., 120.,  20., 239.,  21., 234., 243., 243.,  18.,  19.,  15.,
        243., 226., 233., 237., 234., 222., 223., 219., 220., 137., 163., 212.,
        212.,  28.,   1.,  21.,   1., 105., 203., 213.,   5.,  37.,  80., 117.,
        218., 151.,  65., 216., 135., 134., 243., 264., 259.,  36., 165., 126.,
        237., 242., 217.,  91., 127., 222., 214., 118., 193., 245., 250., 253.,
        222., 257., 246., 112., 149.,  52.,  42.,  27., 103., 250., 219., 252.,
        202., 222., 166., 182., 246.,  16.,  23., 116., 126.,  48., 216., 230.,
         87.,  22., 158., 197., 127.,  63., 242., 258., 251., 158., 172., 176.,
          1.,   1.,   1.,  24., 201., 213., 212., 201., 207.,  19.,  37.,  10.,
          1.,   1.,   1., 130.,   6., 223., 166., 173., 222., 214., 130.,   1.,
         86.,  60., 231., 229., 171., 156., 144.,  56., 102., 195.,   1.,   9.,
          1.,  41.,   1., 103.,  11., 209.,  13.,  19.,  11.,  36., 263., 206.,
        250., 207., 158., 206.,   1.,   1.,  79., 161., 137., 184., 143., 135.,
        132., 207.,  90., 230.,   3.,   1., 214., 198., 191., 184., 153., 189.,
          1.,  22.,  21.,  14., 159., 230., 185., 141., 165., 242., 241., 247.,
        239.,  76., 124.,   2.,  81., 249., 200., 245., 165., 148.,   1.,   1.,
          1., 243.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1., 250., 226., 228.,  72., 242., 235., 243., 193.,
        166., 232., 202., 214., 243., 223., 225., 223., 196.,   6., 219., 103.,
        121.,  12.,  53.,   5.,  91.,  30.,  68.,   4.,  89.,  59.,  77.,  77.,
        236.,   3.,  27., 135., 226., 239., 241., 256., 235., 234.,  42.,  25.,
         23., 239., 214.,  21., 239., 239., 239., 240., 243., 233., 214., 204.,
         38., 222., 238., 222.,  10., 102., 143., 253., 145., 252., 198., 135.,
        111.,  11.,  22., 126., 210., 196., 207., 163.,  18., 201., 175., 118.,
        172., 228., 115., 223., 199., 236.,  47., 147., 114., 192., 197., 236.,
        219., 185., 222., 227., 228., 141., 230., 201., 240., 225., 204., 231.,
        218., 111., 238.,  34.,  30.,  57.,  29.,  24.,  90.,   1.,  35.,   9.,
         12.,  21.,   9.,   1., 241., 250., 132., 120., 229.,   1., 131., 197.,
        230., 176., 260., 189., 192., 100., 255., 195., 201., 178.,  92., 143.,
        155., 214., 100., 111., 108.,   1.,   1., 207., 164., 178., 199., 209.,
        175., 192., 205.,   5., 203., 197., 241., 238.,  98., 129.,   1., 249.,
        129.,  17., 129.,  67., 144., 100., 105., 185., 252., 256., 193., 232.,
        237., 245., 252.,   1., 256.,   1., 149., 115., 135., 255.,  71., 192.,
        196., 207.,   3.,   1., 191.,  22., 196., 199., 221., 219., 138.,   1.,
         20.,   1.,  10.,  10.,   1.,   1.,   4.,  10., 187., 151., 124., 138.,
         67.,  71.,  36., 196., 114., 144.,  12.,  12.,   5.,  41., 192., 196.,
        215., 212., 207., 211., 146.,  30., 218.,   1., 195., 182., 111.,  96.,
        180., 109., 208., 198., 106., 205.,  36.,   1.,   1.,   1.,   1.,   1.,
          1., 226., 222., 227.,  10., 190., 196.,  60.,  27.,  96.,  52., 128.,
        199., 112., 106.,   9.,  94., 119.,  85.,  81., 193., 205., 137., 164.,
        104.,   6.,   1.,   1.,   1., 228., 201., 178., 174., 180., 177., 112.,
        227., 234., 234., 228.,  90., 207.,  61.,  28., 184., 237., 229., 242.,
         11., 225., 234., 209., 234., 235., 246., 246., 207., 241., 167.,  77.,
        233., 246., 239.,  85.,  86., 198., 238., 193.,  23.,  41.,  29.,  68.,
        166., 119., 128., 110., 169.,   1., 106.,  41., 210., 148., 197., 152.,
         31.,  16.,  35., 176., 176.,   1.,   1., 169., 104., 118.,  96.,  71.,
        119.,  82., 114., 229.,   1.,   1., 195.,  56.,  23., 235., 188., 242.,
        254., 143.,   1.,   1.,  65., 135., 241., 253.,  94.,  83., 251., 249.,
          1., 131., 150.,  34., 195.,  45.,  13.,   5.,   1.,   1.,   1.,   1.,
         36., 114.,   1.,   1.,   9.,  52., 152.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.])
mr: 132.6058349609375
mrr: 0.14311964809894562
h1: 0.12576687335968018
h3: 0.1319018453359604
h5: 0.14417177438735962
h10: 0.16564416885375977
==================================

Done Testing!
done with training and eval
Experiments took 38 seconds
