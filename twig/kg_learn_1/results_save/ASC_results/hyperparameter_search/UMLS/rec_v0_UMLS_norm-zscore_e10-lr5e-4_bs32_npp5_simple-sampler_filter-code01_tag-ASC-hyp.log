['run_exp.py', '0', 'UMLS', '10', '5e-4', 'zscore', '32', '5', '0', '1', 'simple', '1']
loading NN
done loading NN
loading dataset
UMLS
X_p: torch.Size([5216, 37])
X_p: torch.Size([661, 37])
X_p: torch.Size([652, 37])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
loading precalculated corruptions from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 10
Epoch 1 -- batch 0 / 163 loss: 0.1641238033771515
Epoch 2 -- batch 0 / 163 loss: 0.10272898524999619
Epoch 3 -- batch 0 / 163 loss: 0.052330028265714645
Epoch 4 -- batch 0 / 163 loss: 0.05155911669135094
Epoch 5 -- batch 0 / 163 loss: 0.04162329062819481
NOT Saving checkpoint at epoch 5
Epoch 6 -- batch 0 / 163 loss: 0.05946345254778862
Epoch 7 -- batch 0 / 163 loss: 0.07157408446073532
Epoch 8 -- batch 0 / 163 loss: 0.04911714792251587
Epoch 9 -- batch 0 / 163 loss: 0.03215126320719719
Epoch 10 -- batch 0 / 163 loss: 0.047835562378168106
NOT Saving checkpoint at epoch 10
Done Training!

==================================
Testing (cite this): dataloader for dataset UMLS
Testing (cite this): batch 0 / 21
ranks: tensor([  1.,   6.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          2.,   1.,   1.,   1.,   1.,   4.,   1.,   1.,   1.,   1.,   1.,   1.,
          3.,   1.,   1.,   1.,   1.,   1.,   1.,   1., 245.,   4.,   1.,   1.,
          3.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,  18.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   3.,   1.,   1.,   1.,   1.,   1.,   2.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,  58.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   2.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   4.,   1.,   1.,  58.,   1., 201.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,  93.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   3.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   4.,   1.,   1.,   1.,   1.,  50., 198.,   1.,   2.,   1.,   1.,
          1.,   1.,   2.,  11.,   1.,  29.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   7.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,  58.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,  20.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1., 232.,  66., 135.,
          1.,   1.,   1.,   3.,   1.,   1.,  58.,   1.,   1.,   1.,   1.,  49.,
          5., 155.,   4.,   1.,   1.,  14.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1., 172.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   3.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,  96.,   4.,   7.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   8.,   1.,   1.,
          1.,   1.,   1.,   1.,  10.,   1.,   1.,   1.,   1., 250.,   1.,   1.,
          1.,   1.,   1.,   1., 144.,   1.,   2.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          3.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   4.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   7.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,  91.,   6.,
          1.,  89.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   7.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,  21.,   1.,   1.,   2.,   1.,   1.,
          9.,   1., 110.,  30.,   1.,   1.,   1.,   1.,   1.,   1.,   3.,   1.,
         60.,   3.,   2.,   2.,  98.,   1.,  15.,  23.,   1.,   1.,   1.,   1.,
          1.,   1.,   2.,   4.,   2.,   1.,   1.,   1.,   1.,   2.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
        254.,   1.,   1.,   1.,   1.,  22.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,
          1.,   1.,   1.,   1.,   2.,   2.,   1.,   1.,   1.,   5.,   1.,   1.,
          1.,   1.,   1.,   1.])
mr: 6.078220844268799
mrr: 0.9055776596069336
h1: 0.8834356069564819
h3: 0.9187116622924805
h5: 0.9340490698814392
h10: 0.9478527903556824
==================================

Done Testing!
done with training and eval
Experiments took 36 seconds
