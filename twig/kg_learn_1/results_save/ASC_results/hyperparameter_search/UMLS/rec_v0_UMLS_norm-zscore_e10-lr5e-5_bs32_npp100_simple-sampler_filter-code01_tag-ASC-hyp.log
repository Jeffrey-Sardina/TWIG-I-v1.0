['run_exp.py', '0', 'UMLS', '10', '5e-5', 'zscore', '32', '100', '0', '1', 'simple', '1']
loading NN
done loading NN
loading dataset
UMLS
X_p: torch.Size([5216, 37])
X_p: torch.Size([661, 37])
X_p: torch.Size([652, 37])
done loading dataset
loading filters
done loading filters
loading negative samplers
loading triple features from cache
loading precalculated corruptions from cache
done loading negative samplers
Running in hyperparameter evaluation mode
TWIG will be evaulaited on the validation set
and will not be tested each epoch on the validation set
running training and eval
TWIG_KGL_v0(
  (linear_struct_1): Linear(in_features=22, out_features=10, bias=True)
  (relu_1): ReLU()
  (dropout_1): Dropout(p=0.01, inplace=False)
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (dropout_2): Dropout(p=0.01, inplace=False)
  (linear_final): Linear(in_features=10, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
REC: Training with epochs = 10
Epoch 1 -- batch 0 / 163 loss: 0.17981742322444916
Epoch 2 -- batch 0 / 163 loss: 0.1493767499923706
Epoch 3 -- batch 0 / 163 loss: 0.10340145230293274
Epoch 4 -- batch 0 / 163 loss: 0.10241397470235825
Epoch 5 -- batch 0 / 163 loss: 0.09842830151319504
NOT Saving checkpoint at epoch 5
Epoch 6 -- batch 0 / 163 loss: 0.12183981388807297
Epoch 7 -- batch 0 / 163 loss: 0.09848302602767944
Epoch 8 -- batch 0 / 163 loss: 0.11336995661258698
Epoch 9 -- batch 0 / 163 loss: 0.10655861347913742
Epoch 10 -- batch 0 / 163 loss: 0.12940460443496704
NOT Saving checkpoint at epoch 10
Done Training!

==================================
Testing (cite this): dataloader for dataset UMLS
Testing (cite this): batch 0 / 21
ranks: tensor([179., 230.,  91., 144.,  62.,   1.,   1.,   1.,  10.,  36.,  47.,  20.,
         13., 113., 120.,  89., 187.,  27.,  18., 208., 255., 169., 108.,  13.,
        211., 164.,  82.,   7.,  86.,   1.,   1.,   1., 250., 145., 240., 124.,
        244., 244., 250., 158., 231., 229., 234., 235., 227., 144., 241., 242.,
        255.,  61.,  63.,  11., 226.,  21., 240., 242., 241.,   9.,  12.,  16.,
        243.,  56., 236., 243., 242., 220., 224., 198., 217.,  89., 128., 207.,
        114.,   4.,   1.,   2.,   1., 153., 203., 210.,   3.,  26.,  15., 126.,
        218.,  92.,  17., 195., 127.,  60.,  42.,   1.,   1.,  48., 130.,  31.,
        236., 241., 244., 241., 195., 235., 245., 244., 243., 246., 250., 253.,
        192., 249., 119.,  99., 205., 236., 245., 220., 248., 255., 252., 257.,
        247., 244.,  30., 138., 241.,   8.,  15.,   8.,  12.,  16., 184.,  92.,
         12.,   1.,   7.,  27., 125., 144., 248., 258., 250.,   3., 204., 192.,
          1.,   2.,   1.,  82., 182., 180., 212., 174., 207.,   3., 183., 173.,
        100.,  85.,  91.,  32., 119., 223., 123.,  72., 222., 161.,  85.,   1.,
         21.,  23., 231., 229.,  26., 161., 151.,  49., 178., 163.,  23.,   9.,
         20.,   3.,  43.,   8.,   1.,   1., 246., 122.,   1.,  14.,   1.,   1.,
        242., 176.,  34., 214.,   1.,   1.,  15., 126.,  20.,  94.,  47., 132.,
         12., 192.,  68., 230.,   4.,   9., 188., 198., 176., 191., 190., 178.,
          1., 140., 126., 116., 113., 230.,   8.,   1., 128., 217., 220., 244.,
        226., 155., 150.,  25., 130., 243., 121.,  35., 244., 135., 244., 229.,
        240., 241., 115., 110.,  23., 134., 237., 226., 235., 246., 226., 255.,
        255., 255.,  69.,   1., 226., 188., 234.,  55., 243., 240., 243.,  22.,
        120., 236., 228., 219., 243., 237., 225., 223.,  44.,   1., 207.,  42.,
         37.,  24.,   2.,   3.,   5.,  35.,  63.,   1.,  22.,  51.,  54.,  31.,
        236.,   1.,  19., 135.,  93., 126., 118., 256., 233., 226.,  23.,  16.,
         13., 230.,  28.,   8., 241., 234., 234., 237., 219.,  73., 185., 122.,
        102., 231., 240., 205.,   1.,  14., 182.,   1.,   1., 252., 201., 135.,
         25.,   5.,  18.,  64., 209., 171., 207., 200., 103., 190., 121., 180.,
        175., 228.,  93., 223., 193., 236., 107., 191.,  52., 143., 125., 235.,
        224., 101.,   1.,   1., 156., 171., 253., 253., 256., 226., 193., 238.,
        212., 210., 200., 217., 186., 214., 182., 129., 216.,  10.,  20.,   1.,
         18.,  15.,  12.,   1., 240.,  43.,  53.,   7.,  22.,  22., 135.,   1.,
        260., 252., 260., 249., 224., 176., 255., 249., 249., 249., 221.,  41.,
        162., 193.,   1., 127., 134.,  55.,  80., 152., 109., 115., 207.,  27.,
          1.,  19.,  18.,  18.,  21.,  18., 136.,   1.,  18.,  96.,   1., 226.,
        233.,  64.,  29.,  24.,  14., 250.,  23., 103., 255., 256., 144., 248.,
        244., 244., 256.,  10., 254.,   1., 150.,  17., 133., 255.,  77., 217.,
        199., 130.,   2.,   2., 191.,  23., 191.,   7., 211., 205.,  27.,   1.,
          1.,   1.,   1.,   1.,   1.,   1.,   1.,   4., 139.,  97.,   1.,   6.,
         78., 107.,   7., 203., 203.,   8.,  73.,  95.,  78., 109.,   1.,   1.,
        223., 215., 221., 221., 137., 175., 207.,   1., 209., 195.,   6.,  81.,
        189.,  84., 177., 199., 134., 220., 240., 239., 243.,  14.,  91., 232.,
        152., 211., 209., 223.,   2., 142., 175.,  15.,  17.,  76.,  93.,   7.,
        192., 132., 135.,  18., 105., 172., 144.,   5., 182., 203.,  21.,  63.,
          8.,   3.,   1.,   1.,   1., 235., 200., 171., 172., 130., 131., 112.,
        226., 232.,   1.,   1.,  84., 218.,  34., 191., 204., 237., 231., 242.,
         59., 231., 236., 195., 220., 246., 246., 246., 210., 242., 184., 159.,
        246., 246., 242.,  79.,  76.,  86., 233.,  93.,  56.,  87.,   3.,  36.,
        118., 176.,  92., 102., 169.,   5.,  32.,  42., 202., 167., 187.,  23.,
          2.,   1., 132., 177., 155.,   1.,   3.,  78., 112.,  78.,  14.,  67.,
        166., 204.,  38., 203.,   1.,   1.,   1.,   1.,  18.,  54.,  26., 190.,
        254., 137.,   1.,  13.,  18., 135., 253., 253.,  10.,  14., 185., 190.,
          1.,   1., 160.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   4.,
          1.,  31.,   1.,   1.,   2., 100., 241., 143.,  33., 248., 218.,  59.,
        106., 124.,  73.,  33.])
mr: 123.05061340332031
mrr: 0.14696167409420013
h1: 0.11809816211462021
h3: 0.14263804256916046
h5: 0.1549079716205597
h10: 0.18865031003952026
==================================

Done Testing!
done with training and eval
Experiments took 58 seconds
